# -*- coding: utf-8 -*-
"""Copy of BDC project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o0VNG5uARR8VsjaR7iKzsNXYZtArYxeV

# Part 1
"""

import pandas as pd #only used this if I wanted to look at the df with cols

#Next order of business here is to figure out how to filter

!git clone https://github.com/1ellejade/Proj1

with open("/content/Proj1/shot_logs.csv",'r')  as f:
  lines = f.readlines()

for line in lines:
  print(line)

import re
import sys

#first map: k=(A, B), v=shot result (change to binary)
pat = re.compile('(?P<hit>m\w+),"(?P<B>\w+,\s\w+)",\d+,\d+\.\d,\d,\d,(?P<A>\w+\s\w+),\d+')
  
with open('data.log', 'w') as g:
  
  for line in lines:
      match = pat.search(line)
      if match:
          if match.group('hit')=='made':
            hit=1
          else:
            hit=0
          g.write('%s\t%s' % ((match.group('A') + '; ' + match.group('B')), hit))
          g.write('\n')

#results of first map

with open('data.log', 'r') as g:
  lines = g.readlines()

for line in lines:
  line=line.strip(',')
  print (line)

#first reduce will compile sum of shot result and sum of total instances
#first reduce: k=(A,B) v=(sum of shot results)/(total shots taken), shots taken
#this will give the fear score for every single pair of players


#first reduce

from operator import itemgetter
import sys

dict_hit_rate = {}

with open('data.log', 'w') as g: #this line change for submission
  
  for line in lines:
    line = line.strip()
    players, hit = line.split('\t')
    try:
        hit=int(hit)
        if dict_hit_rate.get(players) is None:
          dict_hit_rate[players]=(0,0)

        dict_hit_rate[players] = (dict_hit_rate.get(players)[0] + hit, dict_hit_rate.get(players)[1] + 1)


    except ValueError:
        pass

new_dict={}
for key in dict_hit_rate:
  new_dict[key]=dict_hit_rate[key][0]/dict_hit_rate[key][1]

sorted_dict_hit_rate = sorted(new_dict.items(), key=itemgetter(0))

with open('data.log', 'w') as g:
  for players, rate in sorted_dict_hit_rate:
    g.write('%s\t%s' % (players, (round(rate, 2), dict_hit_rate.get(players)[1])))
    g.write('\n')

#results of first reduce

with open('data.log', 'r') as g:
  lines = g.readlines()

for line in lines:
  line=line.strip(',')
  print (line)

#Map 2
#second map: k=(A), v=(B, fear score)


from operator import itemgetter
import sys

with open('data.log', 'w') as g:
  
  for line in lines:
    line = line.strip().split('\t')
    players, rate = line
    
    A, B = players.split('; ')
    #print(hr)

    rate=rate[1:-1]
    rate=rate.split(',')
    rate, shots = rate
    if int(shots)>3:
      g.write('%s\t%s' % (A, (B, rate, shots)))
      g.write('\n')

#results second map

with open('data.log', 'r') as g:
  lines = g.readlines()

for line in lines:
  line=line.strip(',')
  print (line)

#Reduce 2
#second reduce: k=(A), v=(B with the highest fear score)
#so here we will have to sort by 2nd value

from operator import itemgetter
from collections import defaultdict
import sys

defs = defaultdict(list)

with open('data.log', 'w') as g:
  
  for line in lines:
    line = line.strip().split('\t')
    A, B_rate_count = line
    
    B, rate, count = B_rate_count.split('\',')
    B=B[2:]
    rate=rate[2:]
    count=count[2:-2]
    try:
      rate = float(rate)
      count=int(count)    
      defs[A].append([B, rate, count])

    except ValueError:
      pass 

  for player in defs:
    top_n = sorted(defs[player], key=lambda v:(v[1], -v[2]))[0:1]
    print(player, top_n)
    g.write('%s\t%s' % (player, top_n[0][0]))
    g.write('\n')

#results second reduce

with open('data.log', 'r') as g:
  lines = g.readlines()

for line in lines:
  line=line.strip(',')
  print (line)

'''
shots taken duringthe 2014-2015 season, who took the shot, where on the floor was the shot taken from, 
who wasthe nearest defender, how far away was the nearest defender, time on the shot clock, and much more. 
The column titles are generally self-explanatory.

The above figure shows several records, 
where each row represents a shot and the columns arethe details of the shot, e.g. the game ID, 
who is the defender, what is the distance betweenthem

'''

#####PART 1#####
'''
By analyzing the data, we need to answer the following,

  • For each pair of the players (A, B), we define the fear score of A when facing B is the hit rate, 
  such that B is closet defender when A is shooting. Based on the fear score, for each 2 players, 
  please find out who is his ”most unwanted defender”.
'''

#hit rate is #hits/#total shots

#######OUTPUTS FOR M/R#######

#first map: k=(A, B), v=shot result (change to binary)
  #first reduce will compile sum of shot result and sum of total instances
#first reduce: k=(A,B) v=(sum of shot results)/(total shots taken)
  #this will give the fear score for every single pair of players

#second map: k=(A), v=(B, fear score)
  #second reduce input will be k=(A), v=(list of (B, fear score))
#second reduce: k=(A), v=(B with the highest fear score)
  #so here we will have to sort by 2nd value

for col in df:
  print(col, end=',')

map1=pd.DataFrame(columns=['players', 'result'])
map1['players']=str(df['player_name'])+str(df['CLOSEST_DEFENDER'])
map1

"""# Part 2"""

'''
 • For each player, we define the comfortable zone of shooting is a matrix of,
                {SHOT DIST, CLOSE DEF DIST, SHOT CLOCK} 
  Please develop a MapReduce-based algorithm to classify each player’s records into 4 comfortable zones. 
  Considering the hit rate, which zone is the best for James Harden, Chris Paul, Stephen Curry and Lebron James?
'''
#                                                                         #                              #                  #                                                          #                    #
#GAME_ID,MATCHUP,LOCATION,W,FINAL_MARGIN,SHOT_NUMBER,PERIOD,GAME_CLOCK,SHOT_CLOCK,DRIBBLES,TOUCH_TIME,SHOT_DIST,PTS_TYPE,SHOT_RESULT,CLOSEST_DEFENDER,CLOSEST_DEFENDER_PLAYER_ID,CLOSE_DEF_DIST,FGM,PTS,player_name,player_id,

#my idea: output top 4 zones by EITHER # instances or hit rate

#assumptions:
  #comfortable zone is the 'zone' in which they shoot the most frequently. 
  #each player has a top 4 comfortable zones
  #we will have to bin distance, defender distance, shot clock



#####OUTPUT######
'''P1'''
#map: k=(player, binned zone), v=(result, 1)                  #MIGHT WANT TO DO BINNING IN REDUCE so no data loss
  #where result is 0 or 1   
  #sum the v in reduce
#reduce: k=(player, binned zone), v=(total result, total shots), top 4 by total # of shots
  #should my bins be made by taking the range of each attribute and dividing them?

'''P2, requires P1 first'''
#map2: k=player, v=(binned zone, hit rate)
#reduce2: k=player, v=(best zone, best hit rate)
  #this will sort by hit rate and pluck out the first one

with open("/content/Proj1/shot_logs.csv",'r')  as f:
  lines = f.readlines()

for line in lines:
  print(line)

import re
import sys

#map: k=(player), v=(zone, (result, 1))  
  #where result is 0 or 1

pat = re.compile('(?P<clock>\d+\.\d),\d,\d\.\d,(?P<sh_dist>\d+\.\d),\d,(?P<hit>m\w+),"\w+,\s\w+",\d+,(?P<B_dist>\d+\.\d),\d,\d,(?P<A>\w+\s\w+),\d+')
  
with open('data.log', 'w') as g:
  
  for line in lines:
      match = pat.search(line)
      if match:
          if match.group('hit')=='made':
            hit=1
          else:
            hit=0
          g.write('%s\t%s' % ((match.group('A') + ': ' + (match.group('sh_dist')+' '+match.group('B_dist')+' '+match.group('clock'))), (hit,1)))
          g.write('\n')

#results of first map

with open('data.log', 'r') as g:
  lines = g.readlines()

for line in lines:
  line=line.strip(',')
  print (line)

#K-MEANS NOTES/IDEAS

# Step 1: Select K points at random (Centers)
# Step 2: For each data point, assign it to the closest center▸Now we formed K clusters
# Step 3: For each cluster, re-compute the centers
  # E.g., in the case of 2D points 
    # X: average over all x-axis points in the cluster
    # Y: average over all y-axis points in the cluster
    # and... you'll need to calc an average z also
# Step 4: If the new centers are different from the old centers (previous iteration) Go to Step 2


#how do you iterate the parallel one? like how do we know when its done??
#also is the final resulting "zone" supposed to just be the centroid value?


#IDEAS:
#can maybe add all the data to a list and then run the alg in reduce
#also make sure to keep the hit rate in there so you can aggregate it later

#COPY TO EDIT FOR K-MEANS

#reduce: k=(player), v=(list of zones & result)

from operator import itemgetter
import sys

dict_hit_rate = {}

with open('data.log', 'w') as g: #this line change for submission
  
  for line in lines:
    line = line.strip()
    players, hit = line.split('\t')
    try:
        hit=int(hit)
        if dict_hit_rate.get(players) is None:
          dict_hit_rate[players]=(0,0)

        dict_hit_rate[players] = (dict_hit_rate.get(players)[0] + hit, dict_hit_rate.get(players)[1] + 1)


    except ValueError:
        pass

for key in dict_hit_rate:
  dict_hit_rate[key]=dict_hit_rate[key][0]/dict_hit_rate[key][1]

sorted_dict_hit_rate = sorted(dict_hit_rate.items(), key=itemgetter(0))

with open('data.log', 'w') as g:
  for players, rate in sorted_dict_hit_rate:
    g.write('%s\t%s' % (players, round(rate, 2)))
    g.write('\n')

#for line in lines: (bc each line should be for 1 player)
  #make new list of all the zones to be used in the kmeans
  #perform k-means
  #spit out the zones


#might want to opt to deal with hit rate only in the 2nd part and write a new map/reduce taking the results of p1 as an input
  #input centroids, all the same player data as in p1
  #use (player, centroid) as key, find closest centroid to each list item (where the item is the (zone, result))
  #total up results/instances for each centroid and output the maximum value

#reduce: k=(player, binned zone), v=(total result, total shots), top 4 
  #should my bins be made by taking the range of each attribute and dividing them?

from operator import itemgetter
import sys

dict_hit_rate = {}

with open('data.log', 'w') as g: #this line change for submission
  
  for line in lines:
    line = line.strip()
    players, hit = line.split('\t')
    try:
        hit=int(hit)
        if dict_hit_rate.get(players) is None:
          dict_hit_rate[players]=(0,0)

        dict_hit_rate[players] = (dict_hit_rate.get(players)[0] + hit, dict_hit_rate.get(players)[1] + 1)


    except ValueError:
        pass

for key in dict_hit_rate:
  dict_hit_rate[key]=dict_hit_rate[key][0]/dict_hit_rate[key][1]

sorted_dict_hit_rate = sorted(dict_hit_rate.items(), key=itemgetter(0))

with open('data.log', 'w') as g:
  for players, rate in sorted_dict_hit_rate:
    g.write('%s\t%s' % (players, round(rate, 2)))
    g.write('\n')

#(?P<name>...) Similar to regular parentheses, but the substring matched by the group is accessible via the symbolic group name name.

#. matches any character except new line

#\ Either escapes special characters (permitting you to match characters like '*', '?', and so forth), or signals a special sequence

#(...) Matches whatever regular expression is inside the parentheses, 
#and indicates the start and end of a group; the contents of a group can be retrieved after a match has been performed

#\d  For Unicode (str) patterns: Matches any Unicode decimal digit. This includes [0-9], and also many other digit characters

#*   Causes the resulting RE to match 0 or more repetitions of the preceding RE, 
#as many repetitions as are possible. ab* will match ‘a’, ‘ab’, or ‘a’ followed by any number of ‘b’s.

#? after the quantifier makes it perform the match in non-greedy or minimal fashion; 
#as few characters as possible will be matched. Using the RE <.*?> will match only '<a>'.

#+ Causes the resulting RE to match 1 or more repetitions of the preceding RE. 
#ab+ will match ‘a’ followed by any non-zero number of ‘b’s; it will not match just ‘a’.

#\d+. means a string of decimals followed by anything. IP add. is 4 strings of decimals with . in between.

df=pd.read_csv('/content/Proj1/shot_logs.csv')
df